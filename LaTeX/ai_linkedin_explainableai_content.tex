%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Explainable AI : LinkedIn Posts}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{'SHAP' of you}
GDPR (General Data Protection Regulation) has made users of automated systems like AI, entitled to “meaningful information about the logic involved”.

AI systems can no longer be black-boxes. AI owes explanations to its users. SHAP ('SHapley Additive exPlanations', named after Nobel Laureate, Lloyd Shapley)  is one of the popular ways to discover feature  importance of the AI models, on per prediction basis.


Came across this interesting article by @Wai On (https://www.linkedin.com/in/wai-on-lee-ab6555/) at Towards Data Science, talking about deciphering SHAP plots.

https://towardsdatascience.com/visualizing-ai-8fad4ea70b87

Highly recommended!!

Interested in similar recommendations and their tweet-length brief summaries? They have been open-sourced at https://github.com/yogeshhk/ExplainingAI. 

Intent of such posts is to share my journey of learning and explaining AI with a wider audience, thereby increasing awareness of moving AI in safer and human-intent-aligned manner (effective altruism!!).

Please feel to send comments and suggestions for new topics/articles to my email <firstnamelastname at yahoo dot com>


\#ai \#machinelearning \#datascience \#explainableai \#effectivealtruism \#visxai \#xaiviz \#visualization \#shap \#shapley \#xai
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Seeing is believing}
AI, though powerful and effectives, is not perfect at all. 

AI makes mistakes and if being used of critical applications such as health-care, autonomous cars, can be disastrous. Another problem is that, AI models (say, neural networks) are predominantly black-boxes, making it hard to 'see' what's going on, in case they don't work.


Came across this interesting article by @Ben Dickson (https://www.linkedin.com/in/bendee983) at Tech Talks, talking about peeping inside the neural networks.

https://bdtechtalks.com/2019/03/11/openai-google-neural-networks-visualization/

Highly recommended!!

Interested in similar recommendations and their tweet-length brief summaries? They have been open-sourced at https://github.com/yogeshhk/ExplainingAI. 

Intent of such posts is to share my journey of learning and explaining AI with a wider audience, thereby increasing awareness of moving AI in safer and human-intent-aligned manner (effective altruism!!).

Please feel to send comments and suggestions for new topics/articles to my email <firstnamelastname at yahoo dot com>


\#ai \#machinelearning \#datascience \#explainableai \#effectivealtruism \#visxai \#xaiviz \#visualization 
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Positively shaping AI}
Even after 6 decades of AI, aligning AI systems with human goals and values has not been achieved. 

Basically, AI is not able to mimic human intelligence, yet. But that may not remain so. When super intelligent AI arrives (if it does)  it could have huge impacts, both positive and negative. As AI progress is not linear, its impact may be large and sudden.

Currently, AI, on its own, can’t tell right from wrong , forget making the moral decisions. Its just a relationship, it has discovered from the training data, that's it.  There is a risk of it becoming unpredictable at unseen reality while in use.

If not able to correct it, at least we need to now how AI is predicting the way it is. With this we can see if its on right path, fair, not undergoing attacks, legally correct, etc. There comes XAI (Explainable AI), a good career option.

Here is a wonderful article touching the aspect mentioned above: 
https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/

@Robert Wiblin @800000hrs

\#ai \#ml \#machinelerning \#xai \#explainableai \#career \#datascience
\#machinelearning \#effectivealtruism \#aisafety
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Walk like an \ldots}
@Boston Dynamics has been at the forefront of robotics research, especially those walking, dog like robots. 

By seeing those videos one may get impression that these common actions are all easy. Far from truth. Walking is a very complex balancing act, even biologically for us, then its far more difficult to train robots for doing that.

This challenging feat is being attempted using RL (Reinforcement Learning). Its one of the 3 types of Machine Learning (ML) methods (apart from Supervised and Unsupervised) which trains the system using reward and penalties.

Cassie, the two-legged robot was trained for a range of motions from scratch and claims to be closer to the real-world movements.

More details at: https://www.technologyreview.com/2021/04/08/1022176/boston-dynamics-cassie-robot-walk-reinforcement-learning-ai

@Will Douglas Heaven @Zhongyu Li https://www.linkedin.com/in/zhongyu-li-b2b8aa160/

\#ai \#artificialintelligence \#machinelearning \#robots \#machine \#facerecognition \#voiceassistant \#deeplearning \#aibias \#aiethics \#tech \#technews \#mit \#mittechnologyreview \#technologyreview \#techreview 
\#datascience \#explainableai \#effectivealtruism 

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Is AI inside?}
If your software claims to be powered by AI (Artificial Intelligence) ,
then it should:

If none of the above is true, then think twice before claiming!!

Agree?


(Note: Assuming currently popular usage of the term 'AI' here and not software like rule-based expert systems which are not primarily data driven.)

				\begin{itemize}
				\item be trained on data (no data $==$ no AI-ML).
				\item improve as more data is fed, automatically.
				\item be predictive \& autonomous as much as possible.
				\end{itemize}

\#fakeai \#ai \#aimarketing \#hype \#aihype \#ml \#artificialintelligence \#software \#data \#machinelearning \#aiml \#datascience \#explainableai

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Machine Learning on Graphs}

Graphs, though omnipresent, had shied away from being in Machine Learning domain, in the past.

The reason is, they are different. They are unstructured. Unlike popular tabular (fixed rows and columns) and images (fixed length, width, and channels) data, graphs have variable number of nodes and edges, making them unsuitable as an input to Machine Learning (ML) algorithms. ML needs fixed-dimensioned-vectorized-features. Now, various approaches are getting devised to embed/vectorize graphs as well.

Say, for images, a window (convolution, filter) of fixed size runs over the image, condenses information in a fixed size format to be sent forward for ML. Now in graphs, as each node can have different number of neighbors, a special way of convolution has been devised to condense surround/neighbor’s information. Such, condensed/vectored information of nodes then goes on to build overall graph information (vectors, features, embeddings).

Following articles, at a wonderful site called 'distill.pub', explain Graphs and Convolutions on them.

				\begin{itemize}
				\item Intro: https://distill.pub/2021/gnn-intro/
				\item Convolutions: https://distill.pub/2021/understanding-gnns/
				\end{itemize}

\#machinlearning \#graphs \#neuralnetwork \#deeplearning \#neuralnetworks \#machinelearning \#data \#graphneuralnetwors \#gnns \#ml \#ai \#gcn \#graphconvoution

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Searching by shapes}

Searching by words/phrases is well established and highly popular way of finding what you want. Searching by images is also there, but how about searching by shapes? Interesting as well as challenging, right?

Came across this short article by Physna talking about this upcoming area of true 3D geometric search.

Fascinating personally for me as my initial 2 decades of professional career, along with MS+PhD, before moving to AI-ML-NLP, were in this field.

Paul Powers Jay Marshall

\#3d \#search \#similarity \#geometry

https://www.linkedin.com/pulse/2d-vs-3d-data-why-matter-your-business-physna/

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{'Soft' but 'more golden' labels}

Wonderful research on annotations for Machine Learning problems.

It suggests to label training data, softly, meaning, say in case of Sentiment Analysis, don't label samples as either 100% positive or 100% negative, because in reality its typically not so. There are shades of grey. So, annotate like 80% positive, 20% negative. With this, the claim is that, you need far less training data. Obviously the limitation is that you need more rigorous and more correct annotations.

The training data has to be 'more golden' as it is lesser so relied upon more.

Although an early research but looks promising, more so in Natural Language Processing, where interpretations are ambiguous inherently.

\#MIT \#machinelearning \#data \#training \#research \#classification \#clustering \#deeplearning \#annotation \#naturallanguageprocessing

https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/?utm\_campaign=site\_visitor.unpaid.engagement\&utm\_source=LinkedIn\&utm\_medium=tr\_social

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{'tag-line like title'}

'3-5 lines background/intro'

Came across this wonderful article by @'first authors tag', et al at @'org tag' discussing the same topic.

enumerated point-wise actionable, insights, etc

For more details, have a look at the original article at 'website link'

@'remaining authors tags'

Such past suggestions, along with tweet-length brief summary, have been collected and open-sourced at https://github.com/yogeshhk/ExplainingAI

Intent of such posts is to share my journey of learning and explaining AI with a wider audience, thereby increasing awareness for moving AI in a safer and human-intent-aligned manner (effective altruism!!).

Please feel to send comment and new topics/articles at my email <firstnamelastname at yahoo dot com>

\#ai \#machinelearning \#datascience \#explainableai \#effectivealtruism \#topic1 \#topic2

\end{frame}